---
title: 'ðŸ’­ Ollama'
date: 2023-10-14T02:31:03
templateKey: link
link: https://ollama.ai/
tags:
  - llm
  - ai
published: true

---

> ollama is the easiest to get going local llm tool that I have tried, and seems to be crazy fast.  It feels faster than chat gpt, which has not been the experience I have had previously with running llm's on my hardware.


``` bash
curl https://i.jpillora.com/jmorganca/ollama | bash
ollama serve
ollama run mistral
ollama run codellama:7b-code
ollama list
```



[Original thought](https://ollama.ai/)
